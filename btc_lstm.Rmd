---
title: "Untitled"
output: html_document
---

```{r}
library(car)
library(stargazer)
library(nnet)
library(caret)
library(e1071)
library(readr)
library(MASS)
library(randomForest)
library(rel)
library(psych)
library(keras)
library(tensorflow)
library(jsonlite)
winners <- jsonlite::fromJSON("D:/WD/HROM/dat.dat", flatten=TRUE)

winners$time <- as.POSIXct(winners$time, origin = "2017-09-30T01:40Z[UTC]", tz = "UTC")

winners$time <- as.POSIXct(winners$time/1000, origin = "1970-01-01", tz = "UTC")

getwd()
```

```{r}

library(dplyr)
library(ggplot2)
library(lubridate)
library(stringr)
library(caret)
library(car)
library(stargazer)
library(nnet)

library(e1071)
library(readr)
library(MASS)
library(randomForest)
library(rel)
library(psych)

```

```{r}
x <- c(5, 1, 3, 2, 2, NA)
row_number(x)
min_rank(x)
dense_rank(x)
percent_rank(x)
cume_dist(x)

ntile(x, 2)
ntile(runif(100), 10)
btc <- winners
rm(winners)
rm(x)
rm(dates)


btc$volume_l <- dplyr::lag(btc$volume)
btc <- dplyr::select(btc, -volume_l)


set.seed(4984)
dat = data.frame(time=seq(as.POSIXct("2016-05-01"), as.POSIXct("2016-05-01") + 60*99, by=60),
                 count=sample(1:50, 100, replace=TRUE))

dat$by15 = cut(dat$time, breaks="15 min")
dat.summary = aggregate(count ~ by15, FUN=sum, data=dat)

dat.summary = dat %>% group_by(by15=cut(time, "15 min")) %>%
  summarise(count=sum(count))
```

```{r}
btc$by60 = cut(btc$time, breaks = "60 min")
class(btc$time)

btc_b <- btc %>% group_by(by60 = cut(time, "60 min")) %>%
  summarise(open = first(open), close = last(close),low = min(low), high = max(high), volume = sum(volume), trades = sum(trades))

btc_b <- btc_b %>% mutate(mean_oc = (open+close)/2, mean_hl = (high+low)/2)

btc_b <- btc_b %>% mutate(green=as.numeric(as.factor(as.logical(close>open)))-1)
lm <- lm(mean_oc ~ volume+ trades, data = btc_b)
summary(lm)


btc_b$by60 <- as.POSIXct(btc_b$by60)
class(btc_b$by60)
btc_b$by24 <- btc_b %>% group_by(by1 = cut(by60, "24 hours"))
btc_b$by24 <- cut(btc_b$by60, breaks = "24 hours")

btc_b1 <- btc_b %>% group_by(by24 = cut(by60, "24 hours")) %>%
  summarise(mean_24 = mean(close), sd_24 = sd(close))

btc_a <- inner_join(btc_b, btc_b1, by = "by24")
```


```{r}
library(pracma)
library(caTools)
library(qcc)
library(AutoSEARCH)


y <- movavg(btc_a$close, 24, type = "s")
btc_a$ma <- movavg(btc_a$close, 24, type = "s")
btc_a$ma1 <- runmean(btc_a$close, 24, align = "right")
btc_a$ma_sd <- runsd(btc_a$close, 24, align = "right")

btc_a <- dplyr::select(btc_a, -mean_24, -sd_24, -ma1)

btc_a$bb <- btc_a$ma
btc_a$bb_high <- btc_a$ma+2*btc_a$ma_sd
btc_a$bb_low <- btc_a$ma-2*btc_a$ma_sd
btc_a$bb_high[1] <- btc_a$ma[1]
btc_a$bb_low[1] <- btc_a$ma[1]



btc_a$ma_24_e <- movavg(btc_a$close, 24, type = "e")
btc_a$ma_12_e <- movavg(btc_a$close, 12, type = "e")
btc_a$macd <- movavg((btc_a$ma_12_e - btc_a$ma_24_e), 9, type = "e")


btc_a <- btc_a %>% mutate(typical = (high+low+close)/3 )
btc_a$volume_price <- btc_a$volume * btc_a$typical
btc_a <- btc_a %>% group_by(by24 = cut(by60, "24 hours")) %>%
  mutate(cum_v_p = cumsum(volume_price), cum_v = cumsum(volume))
btc_a <- btc_a %>% mutate(wvap = cum_v_p/cum_v)


k <- ewmaSmooth(btc_a$by60, btc_a$close, lambda = 0.2)
btc_a$ewma <- k[["y"]]

btc_a <- btc_a %>% mutate(green=as.numeric(as.factor(as.logical(close>open)))-1)
```


```{r}
final <- btc_a %>% dplyr::select(by60, green, open, close, low, high, volume, trades, bb, bb_high, bb_low, macd, wvap, ewma)


```


```{r}
mlogit <- multinom(green ~ volume + trades +bb+bb_low+bb_high+macd+wvap+ewma
                   , data = final)
summary(mlogit)


```


```{r}

pred <- predict(mlogit)
table <-table(pred, final$green)
table <- as.matrix(table)
matrix <-confusionMatrix(table)
matrix
length(pred)
```


```{r}
log.model = glm(green ~ volume + trades +bb+bb_low+bb_high+macd+wvap+ewma
                   , data = final, family = binomial(link = 'logit'))
summary(log.model)

pred = predict(log.model, newdata = final, type = "response")
head(pred)
summary(pred)

#quantile(pred, probs = seq(0, 1, by= 0.1))

final$log_out <- pred
```


```{r}
lm <- lm( close ~ log_out+ volume + trades +bb+bb_low+bb_high+macd+wvap+ewma, data = final)
summary(lm)
pred <- predict(lm)
final$pred <- pred


gr3 <- ggplot(final, aes(x = by60))+
  geom_line(aes(y = close, color = "close")) +
  geom_line(aes(y = pred, color = "pred"), linetype = "dashed") +
  scale_colour_manual( values = c)


gr3
```


```{r}
library('forecast')
library("aTSA")
library(tseries)
par(mfrow=c(2,1)) 
ACF_pepsi <- forecast::Acf(diff(final$close), lag.max = 50,type = ('correlation'), plot = TRUE)

stationary.test(diff(final$close), method = "adf", nlag = 50, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(diff(final$bb), method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(final$volume, method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(final$trades, method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(final$macd, method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(diff(final$wvap), method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)
stationary.test(diff(final$ewma), method = "adf", nlag = NULL, type = c("Z_rho", "Z_tau"), output = TRUE)

# stationary - trades, volume, macd
# stationary I1 - close, bb, wvap, evma


adf.test(diff(final$close))



```


```{r}
#hyperparameters
#normalization standard normal
final$close_st_n <- (final$close - mean(final$close))/sd(final$close)
hist(final$close_st_n)

final$volume_st_n <- (final$volume - mean(final$volume))/sd(final$volume)
hist(final$volume_st_n)

final$trades_st_n <- (final$trades - mean(final$trades))/sd(final$trades)
hist(final$trades_st_n)

final$bb_st_n <- (final$bb - mean(final$bb))/sd(final$bb)
hist(final$bb_st_n)

final$macd_st_n <- (final$macd - mean(final$macd))/sd(final$macd)
hist(final$macd_st_n)

final$wvap_st_n <- (final$wvap - mean(final$wvap))/sd(final$wvap)
hist(final$wvap_st_n)

final$ewma_st_n <- (final$ewma - mean(final$ewma))/sd(final$ewma)
hist(final$ewma_st_n)

#unity-based normalization
final$close_n <- (final$close-min(final$close))/(max(final$close)-min(final$close))
hist(final$close_n)

final$volume_n <- (final$volume-min(final$volume))/(max(final$volume)-min(final$volume))
hist(final$volume_n)

final$trades_n <- (final$trades-min(final$trades))/(max(final$trades)-min(final$trades))
hist(final$trades_n)

final$bb_n <- (final$bb-min(final$bb))/(max(final$bb)-min(final$bb))
hist(final$bb_n)

final$macd_n <- (final$macd-min(final$macd))/(max(final$macd)-min(final$macd))
hist(final$macd_n)

final$wvap_n <- (final$wvap-min(final$wvap))/(max(final$wvap)-min(final$wvap))
hist(final$wvap_n)

final$ewma_n <- (final$ewma-min(final$ewma))/(max(final$ewma)-min(final$ewma))
hist(final$ewma_n)

#quantile(final$trades, probs = seq(0, 1, by= 0.0001))
```


```{r}
#quantile(final_cut$trades, probs = seq(0, 1, by= 0.0001))
#quantile(final$volume, probs = seq(0, 1, by= 0.0001))
final_cut <- filter(final, trades < 56831.688)
final_cut <- filter(final_cut, volume < 6.617622e+07)

final_cut$trades_n <- (final_cut$trades-min(final_cut$trades))/(max(final_cut$trades)-min(final_cut$trades))
hist(final_cut$trades_n)

log.model_n = glm(green ~ volume_n  +bb_n++macd_n+wvap_n+ewma_n
                   , data = final_cut, family = binomial(link = 'logit'))
summary(log.model_n)

pred = predict(log.model_n, newdata = final, type = "response")
head(pred)
summary(pred)

pred0.5 <- ifelse(pred > 0.5,1,0)
head(pred0.5)
caret::confusionMatrix(pred0.5, final$green)
```


```{r}

#normalization standard normal
final_cut$close_st_n <- (final_cut$close - mean(final_cut$close))/sd(final_cut$close)
hist(final_cut$close_st_n)

final_cut$volume_st_n <- (final_cut$volume - mean(final_cut$volume))/sd(final_cut$volume)
hist(final_cut$volume_st_n)

final_cut$trades_st_n <- (final_cut$trades - mean(final_cut$trades))/sd(final_cut$trades)
hist(final_cut$trades_st_n)

final_cut$bb_st_n <- (final_cut$bb - mean(final_cut$bb))/sd(final_cut$bb)
hist(final_cut$bb_st_n)

final_cut$macd_st_n <- (final_cut$macd - mean(final_cut$macd))/sd(final_cut$macd)
hist(final_cut$macd_st_n)

final_cut$wvap_st_n <- (final_cut$wvap - mean(final_cut$wvap))/sd(final_cut$wvap)
hist(final_cut$wvap_st_n)

final_cut$ewma_st_n <- (final_cut$ewma - mean(final_cut$ewma))/sd(final_cut$ewma)
hist(final_cut$ewma_st_n)

#unity-based normalization
final_cut$close_n <- (final_cut$close-min(final_cut$close))/(max(final_cut$close)-min(final_cut$close))
hist(final_cut$close_n)

final_cut$volume_n <- (final_cut$volume-min(final_cut$volume))/(max(final_cut$volume)-min(final_cut$volume))
hist(final_cut$volume_n)

final_cut$trades_n <- (final_cut$trades-min(final_cut$trades))/(max(final_cut$trades)-min(final_cut$trades))
hist(final_cut$trades_n)

final_cut$bb_n <- (final_cut$bb-min(final_cut$bb))/(max(final_cut$bb)-min(final_cut$bb))
hist(final_cut$bb_n)

final_cut$macd_n <- (final_cut$macd-min(final_cut$macd))/(max(final_cut$macd)-min(final_cut$macd))
hist(final_cut$macd_n)

final_cut$wvap_n <- (final_cut$wvap-min(final_cut$wvap))/(max(final_cut$wvap)-min(final_cut$wvap))
hist(final_cut$wvap_n)

final_cut$ewma_n <- (final_cut$ewma-min(final_cut$ewma))/(max(final_cut$ewma)-min(final_cut$ewma))
hist(final_cut$ewma_n)


```

```{r}

log.model_st_n = glm(green ~ volume_st_n  +bb_st_n++macd_st_n+wvap_st_n+ewma_st_n
                   , data = final_cut, family = binomial(link = 'logit'))
summary(log.model_st_n)

pred = predict(log.model_st_n, newdata = final_cut, type = "response")
head(pred)
summary(pred)

pred0.5 <- ifelse(pred > 0.5,1,0)
head(pred0.5)
caret::confusionMatrix(pred0.5, final_cut$green)

```


```{r}
log.model_n = glm(green ~ volume_n  +bb_n++macd_n+wvap_n+ewma_n
                   , data = final_cut, family = binomial(link = 'logit'))
summary(log.model_n)

pred = predict(log.model_n, newdata = final_cut, type = "response")
head(pred)
summary(pred)

pred0.5 <- ifelse(pred > 0.5,1,0)
head(pred0.5)
caret::confusionMatrix(pred0.5, final_cut$green)


```


```{r}
library(h2o)
h2o.init()

nn <- dplyr::select(final, green, close_n, volume_n, trades_n, bb_n, macd_n, wvap_n, ewma_n,  close_st_n, volume_st_n, trades_st_n, bb_st_n, macd_st_n, wvap_st_n, ewma_st_n)
nn <- dplyr::select(nn, -by24)
nn <- ungroup(nn)

nn$green <- as.factor(nn$green)
set.seed(666)
train_ind = sample(1:nrow(nn), nrow(nn)*0.8)
test=nn[-train_ind,]
train=nn[train_ind,]


train_nn <- as.h2o(train)
test_nn <- as.h2o(test)

y <- "green"
x <- setdiff(colnames(train_nn),y)


nn_green_n <- h2o.deeplearning(x = x
                            ,y = y
                            ,training_frame = train_nn
                            ,standardize = T
                            ,model_id = "model_1"
                            ,activation = "Tanh"
                            ,epochs = 10
                            ,seed = 333
                            ,nfolds = 5
                            ,variable_importances = T)

h2o.performance(nn_green_n,xval = T)

perf <- h2o.performance(nn_green_n, train=TRUE)
perf
summary(nn_green_n)
h2o.accuracy(perf, thresholds = seq(0.40, 0.6, by= 0.01))

h2o.varimp_plot(nn_green_n,num_of_features = 20)
```

```{r}
nn_green_grid <- h2o.deeplearning(x = x
                            ,y = y
                            ,training_frame = train_nn
                            ,validation_frame = test_nn
                            
                            
                            ,activation = "Rectifier"
                            ,epochs = 100
                            ,seed = 333
                            ,hidden = c(100,100,100)
                            ,nfolds = 5
                            ,stopping_rounds=2
  
                            ,stopping_metric="misclassification"
  
                            ,stopping_tolerance=0.001
                            
                            ,adaptive_rate=F
                            ,rate=0.001
                            ,rate_annealing=2e-6
                            ,momentum_start=0.2
                            ,momentum_stable=0.4
                            
                            ,variable_importances = T
                            ,l1 = 1.0E-5
                            ,l2 = 1.0E-5
                            ,overwrite_with_best_model = T
                            )

h2o.performance(nn_green_grid,valid = T)

h2o.performance(nn_green_grid, train=TRUE)
h2o.confusionMatrix(perf)
summary(nn_green_grid)
h2o.accuracy(perf, thresholds = seq(0.40, 0.6, by= 0.01))

h2o.varimp_plot(nn_green_grid,num_of_features = 20)

nn_pred <-as.h2o(nn)
pred_nn_h2o <-h2o.predict(nn_green_grid, newdata = nn_pred)
pred_nn_h2o <- as.data.frame(pred_nn_h2o)
final$prob <- pred_nn_h2o$p1
final$predict <- pred_nn_h2o$predict
summary(final$prob)
quantile(final$prob, probs = seq(0, 1, by= 0.01))

gr3 <- ggplot(final, aes(x = by24))+
  geom_point(aes(y = prob, color = "blue"))+
  geom_point(aes(y = close_n, color = "red"))

gr3

 
```

```{r}
lstm_data_n <- dplyr::select(final, close_n, green, volume_n, trades_n, bb_n, macd_n, wvap_n, ewma_n,   volume_st_n, trades_st_n, bb_st_n, macd_st_n, wvap_st_n, ewma_st_n, prob)
lstm_data_n <- ungroup(lstm_data_n)
lstm_data_n <- dplyr::select(lstm_data_n, -by24)

lstm_data_st_n <- dplyr::select(final, close_st_n, green, volume_n, trades_n, bb_n, macd_n, wvap_n, ewma_n,   volume_st_n, trades_st_n, bb_st_n, macd_st_n, wvap_st_n, ewma_st_n, prob)
lstm_data_st_n <- ungroup(lstm_data_st_n)
lstm_data_st_n <- dplyr::select(lstm_data_st_n, -by24)

lstm_data <- dplyr::select(final, close, green, volume_n, trades_n, bb_n, macd_n, wvap_n, ewma_n,   volume_st_n, trades_st_n, bb_st_n, macd_st_n, wvap_st_n, ewma_st_n, prob)
lstm_data <- ungroup(lstm_data)
lstm_data <- dplyr::select(lstm_data, -by24)

train_lstm = data.matrix(lstm_data[1:10000,2:15])
train_target_lstm = data.matrix(lstm_data$close[1:10000])
dim(train_lstm) <- c(dim(train_lstm), 1)
train_lstm <- aperm(train_lstm, c(1,3,2))


test_lstm = data.matrix(lstm_data[10001:12500,2:15])
test_target_lstm = data.matrix(lstm_data$close[10001:12500])
dim(test_lstm) <- c(dim(test_lstm), 1)
test_lstm <- aperm(test_lstm, c(1,3,2))


train_lstm_n = data.matrix(lstm_data_n[1:10000,2:15])
train_target_lstm_n = data.matrix(lstm_data_n$close_n[1:10000])
dim(train_lstm_n) <- c(dim(train_lstm_n), 1)
train_lstm_n <- aperm(train_lstm_n, c(1,3,2))

test_lstm_n = data.matrix(lstm_data_n[10001:12500,2:15])
test_target_lstm_n = data.matrix(lstm_data_n$close_n[10001:12500])
dim(test_lstm_n) <- c(dim(test_lstm_n), 1)
test_lstm_n <- aperm(test_lstm_n, c(1,3,2))

train_lstm_st_n = data.matrix(lstm_data_st_n[1:10000,2:15])
train_target_lstm_st_n = data.matrix(lstm_data_st_n$close_st_n[1:10000])
dim(train_lstm_st_n) <- c(dim(train_lstm_st_n), 1)
train_lstm_st_n <- aperm(train_lstm_st_n, c(1,3,2))

test_lstm_st_n = data.matrix(lstm_data_st_n[10001:12500,2:15])
test_target_lstm_st_n = data.matrix(lstm_data_st_n$close_st_n[10001:12500])
dim(test_lstm_st_n) <- c(dim(test_lstm_st_n), 1)
test_lstm_st_n <- aperm(test_lstm_st_n, c(1,3,2))

g <- final
for (i in c(8:32)) {
  for (j in c(1:12511))
  g[j+1,i+24] = g[j,i]
}
k <- g[1:12511,]
k$prob <- final$prob
k$prob.1 <- dplyr::lag(k$prob)
```

```{r}
lstm_lag_data_n <- dplyr::select(k, close_n, green, volume_n.1, trades_n.1, bb_n.1, macd_n.1, wvap_n.1, ewma_n.1,   volume_st_n.1, trades_st_n.1, bb_st_n.1, macd_st_n.1, wvap_st_n.1, ewma_st_n.1, prob.1)
lstm_lag_data_n <- ungroup(lstm_lag_data_n)
lstm_lag_data_n <- dplyr::select(lstm_lag_data_n, -by24)

lstm_lag_data_st_n <- dplyr::select(k, close_st_n, green, volume_n.1, trades_n.1, bb_n.1, macd_n.1, wvap_n.1, ewma_n.1,   volume_st_n.1, trades_st_n.1, bb_st_n.1, macd_st_n.1, wvap_st_n.1, ewma_st_n.1, prob.1)
lstm_lag_data_st_n <- ungroup(lstm_lag_data_st_n)
lstm_lag_data_st_n <- dplyr::select(lstm_lag_data_st_n, -by24)

lstm_lag_data <- dplyr::select(k, close, green, volume_n.1, trades_n.1, bb_n.1, macd_n.1, wvap_n.1, ewma_n.1,   volume_st_n.1, trades_st_n.1, bb_st_n.1, macd_st_n.1, wvap_st_n.1, ewma_st_n.1, prob.1)
lstm_lag_data <- ungroup(lstm_lag_data)
lstm_lag_data <- dplyr::select(lstm_lag_data, -by24)


train_lstm_lag = data.matrix(lstm_lag_data[2:10001,2:15])
train_target_lstm_lag = data.matrix(lstm_lag_data$close[2:10001])
dim(train_lstm_lag) <- c(dim(train_lstm_lag), 1)
train_lstm_lag <- aperm(train_lstm_lag, c(1,3,2))

test_lstm_lag = data.matrix(lstm_lag_data[10002:12501,2:15])
test_target_lstm_lag = data.matrix(lstm_lag_data$close[10002:12501])
dim(test_lstm_lag) <- c(dim(test_lstm_lag), 1)
test_lstm_lag <- aperm(test_lstm_lag, c(1,3,2))

train_lstm_lag_n = data.matrix(lstm_lag_data_n[2:10001,2:15])
train_target_lstm_lag_n = data.matrix(lstm_lag_data_n$close_n[2:10001])
dim(train_lstm_lag_n) <- c(dim(train_lstm_lag_n), 1)
train_lstm_lag_n <- aperm(train_lstm_lag_n, c(1,3,2))

test_lstm_lag_n = data.matrix(lstm_lag_data_n[10002:12501,2:15])
test_target_lstm_lag_n = data.matrix(lstm_lag_data_n$close_n[10002:12501])
dim(test_lstm_lag_n) <- c(dim(test_lstm_lag_n), 1)
test_lstm_lag_n <- aperm(test_lstm_lag_n, c(1,3,2))

train_lstm_lag_st_n = data.matrix(lstm_lag_data_st_n[2:10001,2:15])
train_target_lstm_lag_st_n = data.matrix(lstm_lag_data_st_n$close_st_n[2:10001])
dim(train_lstm_lag_st_n) <- c(dim(train_lstm_lag_st_n), 1)
train_lstm_lag_st_n <- aperm(train_lstm_lag_st_n, c(1,3,2))

test_lstm_lag_st_n = data.matrix(lstm_lag_data_st_n[10002:12501,2:15])
test_target_lstm_lag_st_n = data.matrix(lstm_lag_data_st_n$close_st_n[10002:12501])
dim(test_lstm_lag_st_n) <- c(dim(test_lstm_lag_st_n), 1)
test_lstm_lag_st_n <- aperm(test_lstm_lag_st_n, c(1,3,2))
```

```{r}
model_lstm <- keras_model_sequential()

model_lstm %>%
    layer_lstm(units            = 100, 
               input_shape      = c(1, 14),
               batch_size       = 50,
               return_sequences = TRUE, 
               stateful         = TRUE) %>% 
    layer_lstm(units            = 100, 
               batch_size       = 50,
               return_sequences = TRUE, 
               stateful         = TRUE) %>% 
    layer_lstm(units            = 50, 
               return_sequences = FALSE, 
               stateful         = TRUE) %>% 
    layer_dense(units = 1, activation = "relu") %>% 
    compile(loss = 'mean_squared_error', optimizer = 'Nadam', metrics = 'MSE')
rm(model_lstm)
```

```{r}
lstm <- model_lstm %>% fit(
  train_lstm,
  train_target_lstm,
  batch_size = 500,
  validation_data = list(test_lstm, test_target_lstm),
  epochs = 100
  
)

lstm_n <- model_lstm %>% fit(
  train_lstm_n,
  train_target_lstm_n,
  batch_size = 500,
  validation_data = list(test_lstm_n, test_target_lstm_n),
  epochs = 100
  
)

lstm_st_n <- model_lstm %>% fit(
  train_lstm_st_n,
  train_target_lstm_st_n,
  batch_size = 500,
  validation_data = list(test_lstm_st_n, test_target_lstm_st_n),
  epochs = 100
  
)
rm(lstm_lag)
```

```{r}
lstm_lag <- model_lstm %>% fit(
  train_lstm_lag,
  train_target_lstm_lag,
  batch_size = 50,
  validation_data = list(test_lstm_lag, test_target_lstm_lag),
  epochs = 100
  
)




lstm_lag_n <- model_lstm %>% fit(
  train_lstm_lag_n,
  train_target_lstm_lag_n,
  batch_size = 50,
  validation_data = list(test_lstm_lag_n, test_target_lstm_lag_n),
  epochs = 100
  
)

lstm_lag_st_n <- model_lstm %>% fit(
  train_lstm_lag_st_n,
  train_target_lstm_lag_st_n,
  batch_size = 50,
  validation_data = list(test_lstm_lag_st_n, test_target_lstm_lag_st_n),
  epochs = 100
  
)

summary(model_lstm
        )
print(lstm_lag_st_n)

predictions$predict <-keras_predict(model_lstm,test_lstm_lag_st_n, batch_size = 50)
rm(model_lstm)

predict <- as.matrix(predictions)
predictions <- as.data.frame(lstm_lag_data_n$close_n[10002:12501])
predict <- as.data.frame(predict)

base::colnames(predictions) <- c("close_n", "predict_n", "time")
predictions$time <- final$by60[10002:12501]

gr3 <- ggplot(predictions, aes(x = time))+
  geom_line(aes(y = close_n, color = "close_n")) +
  geom_line(aes(y = predict_n, color = "predict_n"), linetype = "dashed") 
 
gr3

predictions$close <-  predictions$close_n*(max(final$close)-min(final$close)) +min(final$close)
predictions$predicted <-  predictions$predict_n*(max(final$close)-min(final$close)) +min(final$close)

predictions$error <- (predictions$close - predictions$predicted)*(predictions$close - predictions$predicted)


rmse <- nthroot(mean(predictions$error), 2)
sd(predictions$close - predictions$predicted)
close <- xts::xts(predictions$predicted, order.by = predictions$time)

strategy <- Strategy(assets=close, strat="ewma", strat.params=list(20))
prices <-getPrices(strategy, from = NULL, until = NULL, which = NULL)
price <- as.data.frame(prices)

signal <- getSignals(strategy, from = NULL, until = NULL, which = NULL)
signals <- as.data.frame(signal)
signals$type <- ifelse(signals$x >0, "BUY", "SELL")

predictions$price <- price$x
submission <- predictions[2:2500,]
submission$type <- signals$type
submission <- submission %>% dplyr::select(time, type, price)

write_json(submission, path = "D:/WD/HROM/submission", simplifyVector = TRUE)
submission <-toJSON(submission, pretty = TRUE)
getwd()
```